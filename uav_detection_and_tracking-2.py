# -*- coding: utf-8 -*-
"""UAV Detection and Tracking.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AEdNV-Z7ro_E5qOi3wh6tL51FIwKCUCg

UAV Detection and Tracking
Multi-Object Tracking (MOT) is a core visual ability that humans poses to perform kinetic tasks and coordinate other tasks. The AI community has recognized the importance of MOT via a series of competitions.

In this assignment, the object class is drone and the ability to track this object will be demonstrated using Kalman Filters. The assignment will give you the opportunity to apply probabilistic reasoning in the physical security application space.

#Setup your development environment and store the test videos locally
> Downloading Drone Videos locally
"""

!apt update -y
!apt upgrade -y
!pip install -U yt-dlp
!pip install ffmpeg
!pip install srt
!pip install -U openai-whisper
!pip install setuptools-rust
!pip install moviepy

import os
import whisper
import yt_dlp
from moviepy.editor import VideoFileClip

def sanitize_filename(filename):
    # Replace special characters in filename with underscore
    return "".join([c if c.isalnum() or c in " .-_" else "_" for c in filename])

def download_video(video_url, output_path='downloads'):
    # Create the output directory if it doesn't exist
    if not os.path.isdir(output_path):
        os.makedirs(output_path)

    ydl_opts = {
        'format': 'bestvideo+bestaudio/best',
        'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),
        'merge_output_format': 'mp4',  # Ensure the final file is in mp4 format
    }

    # Use yt_dlp to download the video
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info_dict = ydl.extract_info(video_url, download=True)
        # Get the filename that yt_dlp has actually saved the file as
        filename = ydl.prepare_filename(info_dict)
        # Check if the file exists using the actual filename
        if not os.path.exists(filename):
            # Try replacing special characters if the file is not found
            filename = sanitize_filename(filename)
            if not os.path.exists(filename):
                raise FileNotFoundError(f"The video file {filename} was not found. Download may have failed.")
        return filename

def extract_audio(video_path):
    # Extract the audio from the video
    video_clip = VideoFileClip(video_path)
    audio_path = video_path + ".wav"
    video_clip.audio.write_audiofile(audio_path)
    return audio_path

def transcribe_audio(whisper_model, audio_path):
    # Transcribe the audio file using Whisper
    result = whisper_model.transcribe(audio_path)
    return result["text"]

# Function to call the video download and transcription
def transcribe_video_from_url(video_url):
    # Download the video and get the filename
    video_path = download_video(video_url)
    print(f"Downloaded video path: {video_path}")

    # Extract audio from the video
    audio_path = extract_audio(video_path)
    print(f"Extracted audio path: {audio_path}")

    # Load the Whisper model
    model = whisper.load_model("base")

    # Transcribe the audio and get the transcription text
    transcription = transcribe_audio(model, audio_path)
    print(f"Transcription: {transcription}")

    # Clean up the audio file
    os.remove(audio_path)

"""

> Downloading the first Drone Video

"""

if __name__ == "__main__":
    # Replace this with the actual URL input from the user
    input_url = 'https://youtu.be/DhmZ6W1UAv4'
    # Call the function with the URL
    transcribe_video_from_url(input_url)

"""> Downloading the second Drone Video"""

if __name__ == "__main__":
    # Replace this with the actual URL input from the user
    input_url = 'https://youtu.be/YrydHPwRelI'
    # Call the function with the URL
    transcribe_video_from_url(input_url)

import os

# Specify the current file path and the new file path
current_file_path = "/content/downloads/Drone Tracking 1.mp4"
new_file_path = "/content/downloads/drone-video-1.mp4"

# Rename the file
os.rename(current_file_path, new_file_path)

print(f"File renamed to: {new_file_path}")

import os

# Specify the current file path and the new file path
current_file_path = "/content/downloads/Drone tracking 2.mp4"
new_file_path = "/content/downloads/drone-video-2.mp4"

# Rename the file
os.rename(current_file_path, new_file_path)

print(f"File renamed to: {new_file_path}")

"""#Task 1 - Setup your development environment and store the test videos locally (10 points)

Task 1: Drone Object Detection (40 points)
You need to research can use any dataset that can be used to detect the class drone such as the drones used for the test videos. Please be careful to distinguish between the datasets that detect objects from drones to datasets that detect the drones. Your object detector must use a deep learning model but you can use an existing object detector model architecture.

Split the videos into frames and use each frame to present the drone detections you got. Store all images that you had detections in a folder called detections. Write your code in such a way that a number of videos can be processed from a directory and not just these two.
"""

### 1. Mount Google Drive ###

from google.colab import drive

drive.mount('/content/drive')

### 2. Define root directory ###

ROOT_DIR = '/content/drive/MyDrive/Inroduction to Aritifical Intelligence/Programming Assignments/Colab Notebooks/UAV/Datasets/UAV Drones/drone_dataset'

### 3. Install Ultralytics ###

!pip install ultralytics
!pip install torch
!pip install opencv-python
!pip filterpy

### 4. Train model ###
from ultralytics import YOLO
import torch
import os

# Load a model
model = YOLO("yolov8n.pt")  # load pre trained model

DATASETS_DIR = '/content/drive/MyDrive/Inroduction to Aritifical Intelligence/Programming Assignments/Colab Notebooks/UAV/Datasets/UAV Drones/drone_dataset/dataset'

# Use the model
results = model.train(data=os.path.join(DATASETS_DIR, "data.yaml"), epochs=30)  # train the model

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Path to your image
image_path = '/content/runs/detect/train/F1_curve.png'

# Load the image
img = mpimg.imread(image_path)

# Display the image
plt.imshow(img)
plt.axis('off') # to turn off axis
plt.show()

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Path to your image
image_path = '/content/runs/detect/train/train_batch1282.jpg'

# Load the image
img = mpimg.imread(image_path)

# Display the image
plt.imshow(img)
plt.axis('off') # to turn off axis
plt.show()

"""Saving a JPG for every dectecton."""

import os
import cv2
from ultralytics import YOLO

def process_video(video_path, model, threshold=0.5, detections_folder='/content/detections/jpg'):
    # Create a subfolder for each video
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    video_detections_folder = os.path.join(detections_folder, video_name)
    if not os.path.exists(video_detections_folder):
        os.makedirs(video_detections_folder)

    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    if not ret:
        print(f"Failed to read video: {video_path}")
        return

    frame_count = 0
    saved_images = []  # List to store paths of saved images

    while ret:
        results = model(frame)[0]
        drone_detected = False

        for result in results.boxes.data.tolist():
            x1, y1, x2, y2, score, class_id = result

            if score > threshold:
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)
                cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),
                            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)
                drone_detected = True

        if drone_detected:
            save_path = os.path.join(video_detections_folder, f"frame{frame_count}.jpg")
            cv2.imwrite(save_path, frame)
            saved_images.append(save_path)

        ret, frame = cap.read()
        frame_count += 1

    cap.release()

    # Print each saved image path on a new line
    print(f"Saved images for {video_path}:")
    for img_path in saved_images:
        print(img_path)

def main():
    VIDEOS_DIR = '/content/downloads'
    model_path = './runs/detect/train/weights/best.pt'
    model = YOLO(model_path)  # load a custom model

    if not os.path.exists('/content/detections'):
        os.makedirs('/content/detections/jpg')

    for video_file in os.listdir(VIDEOS_DIR):
        if video_file.endswith('.mp4'):  # Check if it's a video file
            video_path = os.path.join(VIDEOS_DIR, video_file)
            process_video(video_path, model)

if __name__ == '__main__':
    main()

import os
from ultralytics import YOLO
import cv2

VIDEOS_DIR = '/content/downloads'
OUTPUT_DIR = '/content/detections/video_detections'


if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

model_path = os.path.join('.', 'runs', 'detect', 'train', 'weights', 'best.pt')
model = YOLO(model_path)
threshold = 0.5

# Process each video file in the directory
for video_file in os.listdir(VIDEOS_DIR):
    if video_file.endswith('.mp4'):
        video_path = os.path.join(VIDEOS_DIR, video_file)
        video_name = os.path.splitext(video_file)[0]
        video_output_folder = os.path.join(OUTPUT_DIR, video_name)
        os.makedirs(video_output_folder, exist_ok=True)

        video_path_out = os.path.join(video_output_folder, f'{video_name}_out.mp4')

        cap = cv2.VideoCapture(video_path)
        ret, frame = cap.read()
        if not ret:
            print(f"Failed to read video: {video_path}")
            continue

        H, W, _ = frame.shape
        out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*'MP4V'), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))

        while ret:
            results = model(frame)[0]
            for result in results.boxes.data.tolist():
                x1, y1, x2, y2, score, class_id = result
                if score > threshold:
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)
                    cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),
                                cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)

            out.write(frame)
            ret, frame = cap.read()

        cap.release()
        out.release()

cv2.destroyAllWindows()



"""#Task 2 - Kalman Filter (50 points)

Use the `filterpy`` library to implement a Kalman filter that will track the drone in the video. You will need to use the detections from the previous task to initialize the Kalman filter.

You need to deliver a number of short videos with each video containing only the frames where the drone is present in the test video and its 2D trajectory shown as a line that connects the pixels that the tracker indicated. You can use the ffmpeg command line tool and OpenCV to superpose the bounding box of the drone on the video as well as plot its trajectory.
"""

import os
import cv2
from collections import deque
from ultralytics import YOLO
from filterpy.kalman import KalmanFilter
from filterpy.common import Q_discrete_white_noise
import numpy as np

def create_kalman_filter(dt=1, r_var=0.1, q_var=1.0):
    kf = KalmanFilter(dim_x=4, dim_z=2)
    kf.F = np.array([[1, dt, 0,  0],
                     [0,  1, 0,  0],
                     [0,  0, 1, dt],
                     [0,  0, 0,  1]])
    kf.P = np.eye(4) * 1000
    kf.H = np.array([[1, 0, 0, 0],
                     [0, 0, 1, 0]])
    kf.R = np.eye(2) * r_var
    kf.Q = Q_discrete_white_noise(dim=4, dt=dt, var=q_var)
    return kf

def moving_average(trajectory, window_size=5):
    smoothed_trajectory = []
    trajectory_list = list(trajectory)
    for i in range(len(trajectory_list)):
        start_index = max(0, i - window_size)
        avg_point = np.mean(trajectory_list[start_index:i+1], axis=0)
        smoothed_trajectory.append(tuple(map(int, avg_point)))
    return smoothed_trajectory

def process_video(video_path, model, threshold=0.5, detections_folder='/content/detections/jpg/kalman', max_trajectory_length=50):
    video_folder = os.path.splitext(os.path.basename(video_path))[0]
    video_detections_folder = os.path.join(detections_folder, video_folder)
    if not os.path.exists(video_detections_folder):
        os.makedirs(video_detections_folder)

    cap = cv2.VideoCapture(video_path)
    ret, frame = cap.read()
    if not ret:
        print(f"Failed to read video: {video_path}")
        return

    frame_count = 0
    kf = create_kalman_filter()
    trajectory = deque(maxlen=max_trajectory_length)

    while ret:
        results = model(frame)[0]
        drone_detected = False

        for result in results.boxes.data.tolist():
            x1, y1, x2, y2, score, class_id = result
            if score > threshold:
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)
                cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),
                            cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)
                drone_detected = True

                measurement = np.array([[x1 + (x2 - x1) / 2], [y1 + (y2 - y1) / 2]])
                kf.predict()
                kf.update(measurement)

                estimated_position = kf.x[:2]
                trajectory.append(tuple(map(int, estimated_position.ravel())))

        # Trajectory visualization
        smoothed_trajectory = moving_average(trajectory, window_size=5)
        for i in range(1, len(smoothed_trajectory)):
            thickness = int(np.sqrt(max_trajectory_length / float(i + 1)) * 2.5)
            cv2.line(frame, smoothed_trajectory[i - 1], smoothed_trajectory[i], (0, 0, 255), thickness)

        if drone_detected:
            save_path = os.path.join(video_detections_folder, f"frame{frame_count}.jpg")
            cv2.imwrite(save_path, frame)

        ret, frame = cap.read()
        frame_count += 1

    cap.release()

    # Video generation
    frame_files = [f for f in os.listdir(video_detections_folder) if f.endswith('.jpg')]
    frame_files.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))

    if not frame_files:
        print(f"No frames found for video: {video_path}")
        return

    first_frame_path = os.path.join(video_detections_folder, frame_files[0])
    first_frame = cv2.imread(first_frame_path)

    if first_frame is None:
        print(f"Error: First frame not found at {first_frame_path}.")
        return

    frame_height, frame_width, _ = first_frame.shape
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    output_video_path = os.path.join(video_detections_folder, "output.mp4")
    out = cv2.VideoWriter(output_video_path, fourcc, 30, (frame_width, frame_height))

    for frame_file in frame_files:
        frame_path = os.path.join(video_detections_folder, frame_file)
        frame = cv2.imread(frame_path)
        if frame is not None:
            out.write(frame)

    out.release()

def main():
    VIDEOS_DIR = '/content/downloads/'
    model_path = './runs/detect/train/weights/best.pt'
    model = YOLO(model_path)  # Load a custom model

    for video_file in os.listdir(VIDEOS_DIR):
        if video_file.endswith('.mp4'):
            video_path = os.path.join(VIDEOS_DIR, video_file)
            process_video(video_path, model)

if __name__ == '__main__':
    main()


    out.release()

def main():
    VIDEOS_DIR = '/content/downloads/'
    model_path = './runs/detect/train/weights/best.pt'
    model = YOLO(model_path)  # Load a custom model

    for video_file in os.listdir(VIDEOS_DIR):
        if video_file.endswith('.mp4'):
            video_path = os.path.join(VIDEOS_DIR, video_file)
            process_video(video_path, model)

if __name__ == '__main__':
    main()